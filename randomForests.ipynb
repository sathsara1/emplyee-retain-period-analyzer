{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmK4V4l1VMJxqXC9hTmX8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sathsara1/emplyee-retain-period-analyzer/blob/random-forests/randomForests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FA2dVi9F9qxM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import warnings\n",
        "import mlcroissant as mlc\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_explore_data():\n",
        "\n",
        "    try:\n",
        "        croissant_dataset = mlc.Dataset('https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset/croissant/download')\n",
        "\n",
        "        record_sets = croissant_dataset.metadata.record_sets\n",
        "\n",
        "        record_set_df = pd.DataFrame(croissant_dataset.records(record_set=record_sets[0].uuid))\n",
        "        df = record_set_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset from Kaggle: {str(e)}\")\n",
        "        return None # Return None if there's an error\n",
        "\n",
        "    print(\"\\n First 5 rows of the dataset:\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"\\n Missing values per column:\")\n",
        "    missing_values = df.isnull().sum()\n",
        "    print(missing_values[missing_values > 0])\n",
        "\n",
        "    print(df.describe())\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "QGF9bKEs92lE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    columns_to_drop = ['EmployeeNumber', 'Over18', 'StandardHours', 'EmployeeCount']\n",
        "    existing_columns_to_drop = [col for col in columns_to_drop if col in df_processed.columns]\n",
        "    if existing_columns_to_drop:\n",
        "        df_processed = df_processed.drop(existing_columns_to_drop, axis=1)\n",
        "\n",
        "    if df_processed.isnull().sum().sum() > 0:\n",
        "        numerical_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
        "        df_processed[numerical_cols] = df_processed[numerical_cols].fillna(df_processed[numerical_cols].median())\n",
        "\n",
        "        categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
        "        for col in categorical_cols:\n",
        "            df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])\n",
        "\n",
        "    label_encoders = {}\n",
        "    categorical_columns = df_processed.select_dtypes(include=['object']).columns\n",
        "\n",
        "    for column in categorical_columns:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[column] = le.fit_transform(df_processed[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "    return df_processed, label_encoders\n"
      ],
      "metadata": {
        "id": "3n2KfR8kBAA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_longevity_target(df):\n",
        "\n",
        "    df_with_target = df.copy()\n",
        "\n",
        "\n",
        "    longevity_score = np.zeros(len(df_with_target))\n",
        "\n",
        "    if 'test.csv/Job+Satisfaction' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['test.csv/Job+Satisfaction'] * 0.3\n",
        "    elif 'JobSatisfaction' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['JobSatisfaction'] * 0.3\n",
        "\n",
        "    if 'test.csv/Work-Life+Balance' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['test.csv/Work-Life+Balance'] * 0.2\n",
        "    elif 'WorkLifeBalance' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['WorkLifeBalance'] * 0.2\n",
        "\n",
        "    if 'test.csv/Performance+Rating' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['test.csv/Performance+Rating'] * 0.1\n",
        "    elif 'PerformanceRating' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['PerformanceRating'] * 0.1\n",
        "\n",
        "    if 'test.csv/Years+at+Company' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['test.csv/Years+at+Company'] * 0.1\n",
        "    elif 'YearsAtCompany' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['YearsAtCompany'] * 0.1\n",
        "\n",
        "    if 'test.csv/Company+Tenure' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['test.csv/Company+Tenure'] * 0.1\n",
        "\n",
        "    if 'test.csv/Number+of+Promotions' in df_with_target.columns:\n",
        "        longevity_score += df_with_target['test.csv/Number+of+Promotions'] * 0.1\n",
        "\n",
        "    if 'test.csv/Attrition' in df_with_target.columns:\n",
        "        attrition_binary = (df_with_target['test.csv/Attrition'] == 1).astype(int)\n",
        "        longevity_score += (1 - attrition_binary) * 0.3\n",
        "    elif 'Attrition' in df_with_target.columns:\n",
        "        longevity_score += (1 - df_with_target['Attrition']) * 0.3\n",
        "\n",
        "    longevity_score = (longevity_score - longevity_score.min()) / (longevity_score.max() - longevity_score.min()) * 10\n",
        "\n",
        "    df_with_target['LongevityScore'] = longevity_score\n",
        "\n",
        "    print(f\"Longevity Score:\")\n",
        "    print(f\"   Mean: {longevity_score.mean():.2f}\")\n",
        "    print(f\"   Std: {longevity_score.std():.2f}\")\n",
        "    print(f\"   Min: {longevity_score.min():.2f}\")\n",
        "    print(f\"   Max: {longevity_score.max():.2f}\")\n",
        "\n",
        "    return df_with_target\n"
      ],
      "metadata": {
        "id": "1SHvK8N_BbZW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_data(df):\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('Employee Data Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "    axes[0, 0].hist(df['LongevityScore'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    axes[0, 0].set_title('Distribution of Longevity Scores')\n",
        "    axes[0, 0].set_xlabel('Longevity Score')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    if 'test.csv/Job+Satisfaction' in df.columns:\n",
        "        axes[0, 1].scatter(df['test.csv/Job+Satisfaction'], df['LongevityScore'], alpha=0.6, color='green')\n",
        "        axes[0, 1].set_title('Job Satisfaction vs Longevity Score')\n",
        "        axes[0, 1].set_xlabel('Job Satisfaction')\n",
        "        axes[0, 1].set_ylabel('Longevity Score')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "    elif 'JobSatisfaction' in df.columns:\n",
        "        axes[0, 1].scatter(df['JobSatisfaction'], df['LongevityScore'], alpha=0.6, color='green')\n",
        "        axes[0, 1].set_title('Job Satisfaction vs Longevity Score')\n",
        "        axes[0, 1].set_xlabel('Job Satisfaction')\n",
        "        axes[0, 1].set_ylabel('Longevity Score')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    if 'test.csv/Attrition' in df.columns:\n",
        "        attrition_data = df.groupby('test.csv/Attrition')['LongevityScore'].mean()\n",
        "        axes[1, 0].bar(['Stayed', 'Left'], attrition_data.values, color=['lightgreen', 'lightcoral'])\n",
        "        axes[1, 0].set_title('Average Longevity Score by Attrition Status')\n",
        "        axes[1, 0].set_ylabel('Average Longevity Score')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    elif 'Attrition' in df.columns:\n",
        "        attrition_data = df.groupby('Attrition')['LongevityScore'].mean()\n",
        "        axes[1, 0].bar(['Stayed', 'Left'], attrition_data.values, color=['lightgreen', 'lightcoral'])\n",
        "        axes[1, 0].set_title('Average Longevity Score by Attrition Status')\n",
        "        axes[1, 0].set_ylabel('Average Longevity Score')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    if 'test.csv/Years+at+Company' in df.columns:\n",
        "        axes[1, 1].scatter(df['test.csv/Years+at+Company'], df['LongevityScore'], alpha=0.6, color='purple')\n",
        "        axes[1, 1].set_title('Years at Company vs Longevity Score')\n",
        "        axes[1, 1].set_xlabel('Years at Company')\n",
        "        axes[1, 1].set_ylabel('Longevity Score')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    elif 'YearsAtCompany' in df.columns:\n",
        "        axes[1, 1].scatter(df['YearsAtCompany'], df['LongevityScore'], alpha=0.6, color='purple')\n",
        "        axes[1, 1].set_title('Years at Company vs Longevity Score')\n",
        "        axes[1, 1].set_xlabel('Years at Company')\n",
        "        axes[1, 1].set_ylabel('Longevity Score')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "                square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
        "    plt.title('Correlation Matrix of Numerical Features', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "N4sImHMsB-MJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_random_forest_model(df):\n",
        "    X = df.drop(['LongevityScore'], axis=1)\n",
        "    y = df['LongevityScore']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=None\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    rf_model = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_train = rf_model.predict(X_train_scaled)\n",
        "    y_pred_test = rf_model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
        "    test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "    train_r2 = r2_score(y_train, y_pred_train)\n",
        "    test_r2 = r2_score(y_test, y_pred_test)\n",
        "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "    print(f\"\\nMODEL PERFORMANCE:\")\n",
        "    print(f\"   Training MSE: {train_mse:.4f}\")\n",
        "    print(f\"   Test MSE: {test_mse:.4f}\")\n",
        "    print(f\"   Training RÂ²: {train_r2:.4f}\")\n",
        "    print(f\"   Test RÂ²: {test_r2:.4f}\")\n",
        "    print(f\"   Training MAE: {train_mae:.4f}\")\n",
        "    print(f\"   Test MAE: {test_mae:.4f}\")\n",
        "\n",
        "    cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
        "    print(f\"   Cross-validation RÂ² scores: {cv_scores}\")\n",
        "    print(f\"   Mean CV RÂ²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "    return rf_model, scaler, X_train, X_test, y_train, y_test, y_pred_test"
      ],
      "metadata": {
        "id": "5tEbeiN5Ci75"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    df = load_and_explore_data()\n",
        "    if df is None:\n",
        "        print(\"Upload the dataset to continue\")\n",
        "        return\n",
        "\n",
        "    # df_processed, label_encoders = preprocess_data(df)\n",
        "\n",
        "    # df_with_target = create_longevity_target(df_processed)\n",
        "\n",
        "    # visualize_data(df_with_target)\n",
        "\n",
        "    # # Step 5: Train Random Forest model\n",
        "    # model, scaler, X_train, X_test, y_train, y_test, y_pred = train_random_forest_model(df_with_target)\n",
        "\n",
        "    # # Step 6: Analyze feature importance\n",
        "    # feature_importance_df = analyze_feature_importance(model, X_train.columns)\n",
        "\n",
        "    # # Step 7: Evaluate model performance\n",
        "    # evaluate_model_performance(y_test, y_pred)\n",
        "\n",
        "    # # Step 8: Example prediction\n",
        "    # print(\"\\n\" + \"=\"*60)\n",
        "    # print(\"ðŸ”® EXAMPLE PREDICTION\")\n",
        "    # print(\"=\"*60)\n",
        "\n",
        "    # # Create a sample employee for prediction\n",
        "    # sample_employee = X_test.iloc[0].to_dict()\n",
        "    # print(\"ðŸ“‹ Sample employee features:\")\n",
        "    # for key, value in sample_employee.items():\n",
        "    #     print(f\"   {key}: {value}\")\n",
        "\n",
        "    # predicted_longevity = predict_employee_longevity(\n",
        "    #     model, scaler, X_train.columns, sample_employee\n",
        "    # )\n",
        "\n",
        "    # print(f\"\\nâœ… Actual longevity score: {y_test.iloc[0]:.2f}\")\n",
        "    # print(f\"âœ… Predicted longevity score: {predicted_longevity:.2f}\")\n",
        "\n",
        "    # print(\"\\nðŸŽ‰ ANALYSIS COMPLETE!\")\n",
        "    # print(\"=\"*80)\n",
        "\n",
        "    # return model, scaler, feature_importance_df"
      ],
      "metadata": {
        "id": "cKz0hdc1_jbV"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}